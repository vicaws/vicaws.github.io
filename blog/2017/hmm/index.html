<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Estimating Hidden Markov Models (HMM) | Victor Wang (汪胜)</title> <meta name="author" content="Victor Wang (汪胜)"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://vicaws.github.io/blog/2017/hmm/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Estimating Hidden Markov Models (HMM)",
      "description": "",
      "published": "December 1, 2017",
      "authors": [
        {
          "author": "Victor Wang",
          "authorURL": "",
          "affiliations": [
            {
              "name": "InFoMM, Oxford",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Victor </span>Wang (汪胜)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Portfolio</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/profile/">Profile</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Menu</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">Publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/repositories/">Repositories</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Estimating Hidden Markov Models (HMM)</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#the-hmm-learning-problem">The HMM learning problem</a></div> <div><a href="#baum-welch-algorithm">Baum-Welch algorithm</a></div> <ul> <li><a href="#compute-maximum-likelihood-estimate">Compute maximum likelihood estimate</a></li> <li><a href="#summary-of-the-baum-welch-algorithm">Summary of the Baum-Welch Algorithm</a></li> </ul> <div><a href="#improvments-in-implementation">Improvments in implementation</a></div> <ul> <li><a href="#scaling">Scaling</a></li> <li><a href="#optimal-initialization">Optimal initialization</a></li> </ul> </nav> </d-contents> <p>The Hidden Markov Model (HMM) assumes the system being modelled to be Markov process with unobserved (i.e. hidden) states. In particular, one problem is to learn the hidden Markov transition matrix and conditional probability on Markov states from a sequence of observations. We explain the Baum-Welch algorithm which finds the maximum likelihood estimate of these parameters of a hidden Markov model given a sequence of observed data.</p> <h2 id="the-hmm-learning-problem">The HMM learning problem</h2> <p>In the HMM learning problem, one learns the hidden transition matrix and conditional probability on states from a sequence of observations.</p> <p>Consider a hidden discrete-time Markov chain with random variables \(X_t\) that take values in a set \(S_X = \{1,\cdots,N\}\) of \(N \in \mathbb{N}\) elements. We assume the time-homogeneous Markov property such that \(\mathbb{P}(X_t|X_{t-1})\) is independent of \(t\), which leads to the definition of the time-independent transition matrix \begin{equation} A = {a_{ij}} = \mathbb{P}(X_t=j|X_{t-1}=i). \end{equation} The initial state distribution is given by \begin{equation} \pi = {\pi_j} = \mathbb{P}(X_1 = j), \quad \sum_{j=1}^N \pi_j = 1. \end{equation} Value of \(X_t\) is not observed directly. Rather, we can observe \(Y_t\) that takes values in a set \(S_Y = \{1,\cdots,M\}\). Moreover, the probability of a certain observation at time \(t\) for state \(j\) is denoted as \begin{equation} b_j(k) = \mathbb{P} (Y_t = k | X_t = j). \end{equation} Taking into account all possible values of \(Y_t\) and \(X_t\), we obtain the \(N \times M\) observation matrix \(B = \{b_j(k)\}\).</p> <p>An observation sequence is given by \(Y = \{Y_1 = y_1\), \(Y_2 = y_2, \cdots, Y_T = y_T\}\). The HMM learning problem is then to estimate the HMM parameters \(A\) and \(B\) based on the observation sequence \(Y\), and the HMM model \(\lambda = (\pi, A, B)\).</p> <h2 id="baum-welch-algorithm">Baum-Welch algorithm</h2> <p>We explain the Baum-Welch algorithm that finds the maximum likelihood estimate of the HMM transition matrix \(A\) and observation matrix \(B\).</p> <h3 id="compute-maximum-likelihood-estimate">Compute maximum likelihood estimate</h3> <p>The maximum likelihood estimate (MLE) of the probability \(a_{ij}\) of a particular transition from state \(i\) to \(j\) is</p> <p>\begin{equation} \hat{a}_{ij} = \frac{\text{expected number of transitions from state } i \text{ to } j}{\text{expected number of transitions from state } i}, \label{eq:MLE_a} \end{equation}</p> <p>and the MLE of the probability \(b_j(k)\) of a given label \(k\) from the observation \(Y\), given a state \(j\), is</p> <p>\begin{equation} \hat{b}_j(k) = \frac{\text{exp number of times in state } j \text{ and observing } k}{\text{exp number of times in state } j}. \label{eq:MLE_b} \end{equation}</p> <p>Therefore, the primary idea of computing \(\hat{a}_{ij}\) and \(\hat{b}_j(k)\) is to count all those “expected” numbers in the equation (\ref{eq:MLE_a}) and (\ref{eq:MLE_b}). The Baum-Welch algorithm iteratively estimates the counts, by initialising with a proper guess of the transition and observation probabilities. The estimated probabilities are then used to derive better and better probabilities in the following iterations.</p> <h3 id="compute-hata_ij-and-hatb_jk">Compute \(\hat{a}_{ij}\) and \(\hat{b}_j(k)\)</h3> <p>Let’s proceed with computing \(\hat{a}_{ij}\). Define the probability \(\xi_t(i,j)\) as the probability of being in state \(i\) at time \(t\) and state \(j\) at time \(t+1\), given the observation sequence and the model \(\lambda\),</p> <p>\begin{equation} \xi_t(i,j) = \mathbb{P} (X_t = i, X_{t+1} = j | Y, \lambda). \end{equation}</p> <p>The expected number of transitions from state \(i\) to \(j\) is then the sum of \(\xi\) over all \(t\). The total expected number of transition from state \(i\) is obtained by summing over all transitions out of state \(i\). Hence,</p> <p>\begin{equation} \hat{a}_{ij} = \frac{\sum_{t=1}^{T-1} \xi_t (i,j)}{\sum_{k=1}^N \sum_{t=1}^{T-1} \xi_t (i,k)}. \label{eq:xi_def} \end{equation}</p> <p>We also need a formula for computing the observation probability \(\hat{b}_j(k)\). Define the probability \(\gamma_t(j)\) as the probability of being in state \(j\) at time \(t\), given the observation sequence and the model \(\lambda\),</p> <p>\begin{equation} \gamma_t(j) = \mathbb{P} (X_t = j | Y, \lambda). \end{equation}</p> <p>This enables us to compute \(\hat{b}_j(k)\). For the numerator, we sum \(\gamma_t(j)\) for all time steps \(t\) in which the observation \(y_t = k\). For the denominator, we sum \(\gamma_t(j)\) over all time steps \(t\). Namely,</p> <p>\begin{equation} \hat{b}_j(k) = \frac{\sum_{y_t = k} \gamma_t(j)}{\sum_{t=1}^{T} \gamma_t(j)}. \label{eq:gamma_def} \end{equation}</p> <h3 id="compute-xi_tij-and-gamma_tj">Compute \(\xi_t(i,j)\) and \(\gamma_t(j)\)</h3> <p>To compute \(\xi\) and \(\gamma\), we need define two more specific probabilities \(\alpha\) and \(\beta\). We define the forward path probability \(\alpha_t(j)\) as the probability of being in state \(j\) after seeing the first \(t\) observations,</p> <p>\begin{equation} \alpha_t(j) = \mathbb{P} (y_1, y_2, \cdots, y_t, X_t = j | \lambda), \end{equation}</p> <p>and, define the backward path probability \(\beta_t (j)\) as the probability of seeing the observations from time \(t+1\) to the end, given that we are in state \(j\) at time \(t\),</p> <p>\begin{equation} \beta_t(j) = \mathbb{P} (y_{t+1}, y_{t+2}, \cdots, y_T | X_t = j, \lambda). \end{equation}</p> <p>By Bayes’ theorem, we can re-write \(\xi\) and \(\gamma\) as</p> <p>\begin{equation} \xi_t(i,j) = \frac{\mathbb{P} (X_t=i,X_{t+1},Y | \lambda)}{\mathbb{P} ( Y | \lambda) }, \quad \gamma_t (j) = \frac{\mathbb{P} (X_t = j, Y | \lambda)}{\mathbb{P} (Y | \lambda)}. \label{eq:xi_gamma_comp} \end{equation}</p> <p>Note that the denominator is the probability of the observation and can be computed in multiple ways,</p> <p>\begin{equation} \mathbb{P} (Y | \lambda) = \sum_{j=1}^N \alpha_T (j) = \sum_{j=1}^N \pi_j \beta_0 (j). \label{eq:ProbObservations} \end{equation}</p> <p>The numerators in (\ref{eq:xi_gamma_comp}) can be expressed in terms of \(\alpha\) and \(\beta\):</p> <p>\begin{equation} \mathbb{P} (X_t=i,X_{t+1},Y | \lambda) = \alpha_t(i) a_{ij} b_j(y_{t+1}) \beta_{t+1} (j), \end{equation} \begin{equation} \mathbb{P} (X_t = j, Y | \lambda) = \alpha_t(j) \beta_t(j). \end{equation}</p> <h3 id="compute-alpha_tj-and-beta_tj">Compute \(\alpha_t(j)\) and \(\beta_t(j)\)</h3> <p>It remains to calculate \(\alpha\) and \(\beta\). From their definitions, we can derive an iteration equation for each. Then we can solve them for all time steps by assigning a starting value. To be specific,</p> \[\alpha_1 (j) = \pi_j b_j(y_1), \text{ } 1 \leq j \leq N,\] <p>\begin{equation} \alpha_t (j) = \sum_{i=1}^N \alpha_{t-1} (i) a_{ij} b_j(y_t), \text{ } 1 \leq j \leq N, 2 \leq t \leq T, \label{eq:ForwardAlgorithm} \end{equation}</p> <p>and,</p> \[\beta_T (j) = 1, \text{ } 1 \leq j \leq N,\] <p>\begin{equation} \beta_t (j) = \sum_{i=1}^N a_{ji} b_i(y_{t+1}) \beta_{t+1}(i), \text{ } 1 \leq j \leq N, 1 \leq t \leq T-1. \label{eq:BackwardAlgorithm} \end{equation}</p> <p>In fact, equation (\ref{eq:ForwardAlgorithm}) is called forward algorithm, and (\ref{eq:BackwardAlgorithm}) is called backward algorithm.</p> <h3 id="summary-of-the-baum-welch-algorithm">Summary of the Baum-Welch Algorithm</h3> <p>Hence, we summarise the algorithm as followings.</p> <blockquote> <p><strong>function</strong> Baum-Welch (observations \(Y = \\{ y_1,\cdots,y_T \\}\), number of hidden states \(N\)):</p> <p>     <strong>initialise</strong> \(A\) and \(B\)</p> <p>     <strong>iterate</strong> until convergence</p> <blockquote> <p>compute \(\alpha_t(j)\) using forward algorithm (\ref{eq:ForwardAlgorithm});</p> <p>compute \(\beta_t(j)\) using backward algorithm (\ref{eq:BackwardAlgorithm});</p> <p>compute \(\xi_t(i,j) = \frac{\alpha_t(i) a_{ij} b_j(y_{t+1})\beta_{t+1}(j)}{\sum_{k=1}^N \alpha_T (k)}\), \(\forall t\) and \(j\);</p> <p>compute \(\gamma_t(j) = \frac{\alpha_t(j) \beta_{t}(j)}{\sum_{k=1}^N \alpha_T (k)}\), \(\forall t\), \(i\) and \(j\);</p> <p>compute \(\hat{a}\_{ij} = \frac{\sum_{t=1}^{T-1} \xi_t (i,j)}{\sum_{k=1}^N \sum_{t=1}^{T-1} \xi_t (i,k)}\), \(\forall i\) and \(j\);</p> <p>compute \(\hat{b}\_j(k) = \frac{\sum_{y_t = k} \gamma_t(j)}{\sum_{t=1}^{T} \gamma_t(j)}\), \(\forall i\) and \(j\);</p> </blockquote> <p><strong>return</strong> \(A\), \(B\)</p> </blockquote> <h2 id="improvments-in-implementation">Improvments in implementation</h2> <p>We have observed some deficiencies of the stated Baum-Welch algorithm during practical implementation. In particular,</p> <ol> <li> <p>Both forward and backward algorithms require computations involving products of probabilities. It is easy to see, for example, \(\alpha_t(j)\) tends to 0 exponentially as \(T\) increases. Therefore, any attempt to implement the formula as given above will inevitably result in underflow.</p> </li> <li> <p>The converged estimates for \(A\) and \(B\) are reasonably believed to be a local rather than the global optimum, so that they are sensitive to the initial guess.</p> </li> </ol> <h3 id="scaling">Scaling</h3> <p>To solve the problem stated in (1), we scale the probabilities calculated in each time step. Instead of calculating \(\alpha_t(j)\) following algorithm (\ref{eq:ForwardAlgorithm}), we compute \(\hat{\alpha}(j)\), in order,</p> \[\tilde{\alpha}_1 (j) = \pi_j b_j(y_1), \text{ } 1 \leq j \leq N,\] \[c_1 = \frac{1}{\sum_{j=1}^N \tilde{\alpha}_1(j)},\] \[\hat{\alpha}\_1 (j) = c_1 \tilde{\alpha}_t (j), \text{ } 1 \leq j \leq N,\] \[\tilde{\alpha}\_t (j) = \sum_{i=1}^N \hat{\alpha}\_{t-1} (i) a_{ij} b_j(y_t), \text{ } 1 \leq j \leq N, 2 \leq t \leq T,\] \[c_t = \frac{1}{\sum_{j=1}^N \tilde{\alpha}_t(j)},\] <p>\begin{equation} \hat{\alpha}_t (j) = c_t \tilde{\alpha}_t (j), \text{ } 1 \leq j \leq N. \label{eq:ForwardAlgorithmScale} \end{equation}</p> <p>To make sure the above-mentioned scaling on \(\alpha\) do not distort the probabilities computed in the following such as \(\xi\) and \(\gamma\), the same scaling are applied to \(\beta\) accordingly. Therefore, instead of computing \(\beta_t(j)\) using algorithm (\ref{eq:BackwardAlgorithm}), we compute \(\hat{\beta}_t (j)\), in order,</p> \[\hat{\beta}_T (j) = c_T, \text{ } 1 \leq j \leq N,\] \[\tilde{\beta}\_t (j) = \sum_{i=1}^N a_{ji} b_i(y_{t+1}) \hat{\beta}_{t+1}(i), \text{ } 1 \leq j \leq N, 1 \leq t \leq T-1,\] <p>\begin{equation} \hat{\beta}_t (j) = c_t \tilde{\beta}_t (j), \text{ } 1 \leq j \leq N. \label{eq:BackwardAlgorithmScale} \end{equation}</p> <h3 id="optimal-initialization">Optimal initialization</h3> <p>The converged estimates for \(A\) and \(B\) are usually local optimum, subject to the choice of initial guess of the model \(\lambda^{(0)} = (\pi^{(0)}, A^{(0)}, B^{(0)})\). To attempt to approach the global optimum, we randomly select a sequence of initial guesses and pick the one that results in the largest probability \(\mathbb{P} (Y \\| \lambda)\), the probability of observing the given sequence.</p> <p>Due to the scaling in the revisited forward algorithm (\ref{eq:BackwardAlgorithmScale}), we use formula (\ref{eq:ProbObservations}) and obtain</p> <p>\begin{equation} \mathbb{P} (Y | \lambda) = \frac{1}{\prod_{t=1}^T c_t}. \end{equation}</p> <p>To avoid underflow, we instead compute</p> <p>\begin{equation} \log[ \mathbb{P} (Y | \lambda) ] = - \sum_{t=1}^T \log c_t. \end{equation}</p> <p>We don’t allow completely randomness of the model, which might largely increase the computational efforts required for the maximisation. We fix</p> <p>\begin{equation} \pi^{(0)}_j = \frac{1}{N}, \text{ } b_j(k) = \frac{1}{M}, \text{ for }\forall j \text{ and } k, \end{equation}</p> <p>and only allow \(a_{ij}\) to be uniformly distributed with respect to \(\sum_j a_{ij} = 1\) for \(\forall i\).</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Victor Wang (汪胜). Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>